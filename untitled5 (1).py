# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LGJBk46N9SjqStqgusBrgBbVgjyq7mld
"""

!pip install keras-tuner

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
import keras_tuner as kt
import matplotlib.pyplot as plt

# ---------------------------
# 1. DATA GENERATION
# ---------------------------
def generate_synthetic_multivariate_series(n_samples=2000):
    t = np.arange(n_samples)
    feature1 = 0.5*np.sin(0.02*t) + 0.3*np.random.randn(n_samples)
    feature2 = 0.3*np.cos(0.015*t + 2) + 0.3*np.random.randn(n_samples)
    trend = 0.001*t
    target = 0.4*feature1 + 0.6*feature2 + trend + 0.2*np.random.randn(n_samples)

    df = pd.DataFrame({"f1": feature1, "f2": feature2, "target": target})
    return df

# ---------------------------
# 2. PREPROCESSING + SEQUENCES
# ---------------------------
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i : i + seq_length, :])
        y.append(data[i + seq_length, -1])
    return np.array(X), np.array(y)

# ---------------------------
# 3. LSTM MODEL BUILDER FOR TUNING
# ---------------------------
def build_model(hp):
    model = keras.Sequential()
    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)
    hp_layers = hp.Int('layers', 1, 3)

    for i in range(hp_layers):
        model.add(layers.LSTM(hp_units, return_sequences=(i < hp_layers - 1)))
        model.add(layers.Dropout(hp.Float('dropout', 0.1, 0.5, step=0.1)))

    model.add(layers.Dense(1))

    hp_lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_lr), loss='mse')
    return model

# ---------------------------
# MAIN SCRIPT
# ---------------------------
if __name__ == '__main__':
    df = generate_synthetic_multivariate_series()
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df)

    SEQ_LEN = 30
    X, y = create_sequences(scaled, SEQ_LEN)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    tuner = kt.RandomSearch(
        build_model,
        objective='val_loss',
        max_trials=5,
        directory='tuner_dir',
        project_name='lstm_opt'
    )

    tuner.search(X_train, y_train, epochs=10, validation_split=0.2)
    best_model = tuner.get_best_models(num_models=1)[0]

    y_pred = best_model.predict(X_test).flatten()
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)

    print("RMSE:", rmse)
    print("MAE:", mae)

    plt.plot(y_test, label='True')
    plt.plot(y_pred, label='Predicted')
    plt.legend(); plt.show()

    # Integrated Gradients for explainability

    # Removed @tf.function decorators as they can sometimes interfere with gradient computation in specific scenarios.
    def interpolate_inputs(baseline, input_tensor, alpha):
        return baseline + alpha * (input_tensor - baseline)

    def compute_gradients(inputs, target_index):
        # Ensure inputs is a TensorFlow Tensor for gradient tracking
        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)
        with tf.GradientTape() as tape:
            tape.watch(inputs)
            # Use training=False for consistent behavior with dropout/batchnorm during inference
            pred = best_model(inputs, training=False)

            # Added checks for pred being None or target_index out of bounds
            if pred is None:
                print("Error: best_model returned None in compute_gradients")
                return None # Propagate None
            if pred.shape[1] <= target_index:
                print(f"Error: target_index {target_index} out of bounds for pred shape {pred.shape}")
                return None # Propagate None

            target_output = pred[:, target_index]

        gradients = tape.gradient(target_output, inputs)
        return gradients

    def integrated_gradients(input_sample, baseline=None, steps=50):
        # Ensure input_sample is a TensorFlow Tensor
        input_sample = tf.convert_to_tensor(input_sample, dtype=tf.float32)

        if baseline is None:
            baseline = tf.zeros_like(input_sample)

        alphas = tf.linspace(0.0, 1.0, steps)
        total_gradients = tf.zeros_like(input_sample, dtype=tf.float32)

        for alpha in alphas:
            x_interp = interpolate_inputs(baseline, input_sample, alpha)
            grads = compute_gradients(x_interp, 0)

            # Handle case where gradients are None to prevent ValueError
            if grads is None:
                print(f"Warning: Gradients are None for alpha={alpha}. Skipping this step in integrated_gradients.")
                continue

            total_gradients += grads

        # Handle case where all gradients were None, to prevent division by zero if steps > 0
        if steps > 0:
            avg_gradients = total_gradients / steps
        else:
            avg_gradients = tf.zeros_like(input_sample) # Or handle as an error if steps is expected > 0

        ig = (input_sample - baseline) * avg_gradients
        return ig.numpy()

    sample = X_test[0:1]
    ig_result = integrated_gradients(tf.convert_to_tensor(sample, dtype=tf.float32))

    print("Integrated Gradients shape:", ig_result.shape)

import tensorflow.keras.backend as K
import tensorflow as tf

def interpolate_inputs(baseline, input_tensor, alpha):
    return baseline + alpha * (input_tensor - baseline)

def compute_gradients(inputs, target_index):
    # Ensure inputs is a TensorFlow Tensor for gradient tracking
    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)
    with tf.GradientTape() as tape:
        tape.watch(inputs)
        pred = best_model(inputs, training=False)

        # Debugging: check if pred is None or has unexpected shape
        if pred is None:
            print("Error: best_model returned None in compute_gradients")
            return None # Propagate None
        if pred.shape[1] <= target_index:
            print(f"Error: target_index {target_index} out of bounds for pred shape {pred.shape}")
            return None # Propagate None

        target_output = pred[:, target_index]

    gradients = tape.gradient(target_output, inputs)
    return gradients

def integrated_gradients(input_sample, baseline=None, steps=50):
    # Ensure input_sample is a TensorFlow Tensor
    input_sample = tf.convert_to_tensor(input_sample, dtype=tf.float32)

    if baseline is None:
        baseline = tf.zeros_like(input_sample)

    alphas = tf.linspace(0.0, 1.0, steps)
    total_gradients = tf.zeros_like(input_sample, dtype=tf.float32)

    for alpha in alphas:
        x_interp = interpolate_inputs(baseline, input_sample, alpha)
        grads = compute_gradients(x_interp, 0)

        if grads is None:
            # If gradients are None, something went wrong; print warning and skip this step
            print(f"Warning: Gradients are None for alpha={alpha}. Skipping this step in integrated_gradients.")
            continue

        total_gradients += grads

    # Handle case where all gradients were None, to prevent division by zero if steps > 0
    if steps > 0:
        avg_gradients = total_gradients / steps
    else:
        avg_gradients = tf.zeros_like(input_sample) # Or handle as an error if steps is expected > 0

    ig = (input_sample - baseline) * avg_gradients
    return ig.numpy()

sample = X_test[0:1]
ig_result = integrated_gradients(tf.convert_to_tensor(sample, dtype=tf.float32))

print("Integrated Gradients shape:", ig_result.shape)